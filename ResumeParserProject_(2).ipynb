{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ResumeParserProject (2)",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1_ucN18X7R247MVDbvyHB7qIoRT0jU3LO",
      "authorship_tag": "ABX9TyO4/zvO4x6BhiBOF55QzHKV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jalalrahmanov/Projects/blob/master/ResumeParserProject_(2).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Welcome!"
      ],
      "metadata": {
        "id": "nQEFKAYt2HvW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-docx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQYhf3uswc3-",
        "outputId": "1d2dcade-f742-4012-daa9-2ff026d1500c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting python-docx\n",
            "  Downloading python-docx-0.8.11.tar.gz (5.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6 MB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from python-docx) (4.2.6)\n",
            "Building wheels for collected packages: python-docx\n",
            "  Building wheel for python-docx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-docx: filename=python_docx-0.8.11-py3-none-any.whl size=184507 sha256=564bdf0a0c76f321abf8840169a8c4ca5483f9d30cc09cf00f431f5ccd96a999\n",
            "  Stored in directory: /root/.cache/pip/wheels/f6/6f/b9/d798122a8b55b74ad30b5f52b01482169b445fbb84a11797a6\n",
            "Successfully built python-docx\n",
            "Installing collected packages: python-docx\n",
            "Successfully installed python-docx-0.8.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install docx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jjnY0uzmw2EN",
        "outputId": "683a16ec-8903-4c2c-f4d4-f209e33a958c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: docx in /usr/local/lib/python3.7/dist-packages (0.2.4)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from docx) (4.2.6)\n",
            "Requirement already satisfied: Pillow>=2.0 in /usr/local/lib/python3.7/dist-packages (from docx) (7.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyresparser"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RLwDJQGlw6Uc",
        "outputId": "02c66697-0b2b-44f0-95d5-d18e1f009ca6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyresparser\n",
            "  Downloading pyresparser-1.0.6-py3-none-any.whl (4.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.2 MB 4.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi>=2019.6.16 in /usr/local/lib/python3.7/dist-packages (from pyresparser) (2022.5.18.1)\n",
            "Collecting nltk>=3.4.3\n",
            "  Downloading nltk-3.7-py3-none-any.whl (1.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5 MB 33.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wasabi>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from pyresparser) (0.9.1)\n",
            "Requirement already satisfied: spacy>=2.1.4 in /usr/local/lib/python3.7/dist-packages (from pyresparser) (2.2.4)\n",
            "Requirement already satisfied: pytz>=2019.1 in /usr/local/lib/python3.7/dist-packages (from pyresparser) (2022.1)\n",
            "Requirement already satisfied: pandas>=0.24.2 in /usr/local/lib/python3.7/dist-packages (from pyresparser) (1.3.5)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from pyresparser) (1.15.0)\n",
            "Requirement already satisfied: blis>=0.2.4 in /usr/local/lib/python3.7/dist-packages (from pyresparser) (0.4.1)\n",
            "Requirement already satisfied: preshed>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from pyresparser) (3.0.6)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.7/dist-packages (from pyresparser) (21.4.0)\n",
            "Requirement already satisfied: pyrsistent>=0.15.2 in /usr/local/lib/python3.7/dist-packages (from pyresparser) (0.18.1)\n",
            "Requirement already satisfied: cymem>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from pyresparser) (2.0.6)\n",
            "Requirement already satisfied: numpy>=1.16.4 in /usr/local/lib/python3.7/dist-packages (from pyresparser) (1.21.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from pyresparser) (2.8.2)\n",
            "Collecting urllib3>=1.25.3\n",
            "  Downloading urllib3-1.26.9-py2.py3-none-any.whl (138 kB)\n",
            "\u001b[K     |████████████████████████████████| 138 kB 50.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: thinc>=7.0.4 in /usr/local/lib/python3.7/dist-packages (from pyresparser) (7.4.0)\n",
            "Requirement already satisfied: jsonschema>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from pyresparser) (4.3.3)\n",
            "Collecting docx2txt>=0.7\n",
            "  Downloading docx2txt-0.8.tar.gz (2.8 kB)\n",
            "Collecting pycryptodome>=3.8.2\n",
            "  Downloading pycryptodome-3.14.1-cp35-abi3-manylinux2010_x86_64.whl (2.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0 MB 31.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna>=2.8 in /usr/local/lib/python3.7/dist-packages (from pyresparser) (2.10)\n",
            "Requirement already satisfied: tqdm>=4.32.2 in /usr/local/lib/python3.7/dist-packages (from pyresparser) (4.64.0)\n",
            "Requirement already satisfied: chardet>=3.0.4 in /usr/local/lib/python3.7/dist-packages (from pyresparser) (3.0.4)\n",
            "Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.7/dist-packages (from pyresparser) (2.23.0)\n",
            "Requirement already satisfied: sortedcontainers>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from pyresparser) (2.4.0)\n",
            "Collecting pdfminer.six>=20181108\n",
            "  Downloading pdfminer.six-20220524-py3-none-any.whl (5.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6 MB 42.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: srsly>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from pyresparser) (1.0.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0.1->pyresparser) (4.2.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0.1->pyresparser) (4.11.4)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0.1->pyresparser) (5.7.1)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources>=1.4.0->jsonschema>=3.0.1->pyresparser) (3.8.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk>=3.4.3->pyresparser) (7.1.2)\n",
            "Collecting regex>=2021.8.3\n",
            "  Downloading regex-2022.4.24-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (749 kB)\n",
            "\u001b[K     |████████████████████████████████| 749 kB 36.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk>=3.4.3->pyresparser) (1.1.0)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from pdfminer.six>=20181108->pyresparser) (2.0.12)\n",
            "Collecting cryptography>=36.0.0\n",
            "  Downloading cryptography-37.0.2-cp36-abi3-manylinux_2_24_x86_64.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 35.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=36.0.0->pdfminer.six>=20181108->pyresparser) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six>=20181108->pyresparser) (2.21)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from preshed>=2.0.1->pyresparser) (1.0.7)\n",
            "Collecting urllib3>=1.25.3\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 39.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.1.4->pyresparser) (57.4.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.1.4->pyresparser) (1.0.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.1.4->pyresparser) (1.1.3)\n",
            "Building wheels for collected packages: docx2txt\n",
            "  Building wheel for docx2txt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docx2txt: filename=docx2txt-0.8-py3-none-any.whl size=3980 sha256=866e57d43bfee3431e32cd20d53865cc4a49cb4afdfe4885a6f0f719d4b9f77c\n",
            "  Stored in directory: /root/.cache/pip/wheels/b7/20/b2/473e3aea9a0c0d3e7b2f7bd81d06d0794fec12752733d1f3a8\n",
            "Successfully built docx2txt\n",
            "Installing collected packages: urllib3, regex, cryptography, pycryptodome, pdfminer.six, nltk, docx2txt, pyresparser\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: regex\n",
            "    Found existing installation: regex 2019.12.20\n",
            "    Uninstalling regex-2019.12.20:\n",
            "      Successfully uninstalled regex-2019.12.20\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.2.5\n",
            "    Uninstalling nltk-3.2.5:\n",
            "      Successfully uninstalled nltk-3.2.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed cryptography-37.0.2 docx2txt-0.8 nltk-3.7 pdfminer.six-20220524 pycryptodome-3.14.1 pyresparser-1.0.6 regex-2022.4.24 urllib3-1.25.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "STOPWORDS = set(stopwords.words('english'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9AfIVKRQyAY1",
        "outputId": "1a023417-3ab5-4e46-f76d-5ad0b05da741"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "stopwords.words('english')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4M6Kz2axsXy",
        "outputId": "734cc97c-29c4-4650-fd71-18be336e5ab4"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i',\n",
              " 'me',\n",
              " 'my',\n",
              " 'myself',\n",
              " 'we',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'you',\n",
              " \"you're\",\n",
              " \"you've\",\n",
              " \"you'll\",\n",
              " \"you'd\",\n",
              " 'your',\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves',\n",
              " 'he',\n",
              " 'him',\n",
              " 'his',\n",
              " 'himself',\n",
              " 'she',\n",
              " \"she's\",\n",
              " 'her',\n",
              " 'hers',\n",
              " 'herself',\n",
              " 'it',\n",
              " \"it's\",\n",
              " 'its',\n",
              " 'itself',\n",
              " 'they',\n",
              " 'them',\n",
              " 'their',\n",
              " 'theirs',\n",
              " 'themselves',\n",
              " 'what',\n",
              " 'which',\n",
              " 'who',\n",
              " 'whom',\n",
              " 'this',\n",
              " 'that',\n",
              " \"that'll\",\n",
              " 'these',\n",
              " 'those',\n",
              " 'am',\n",
              " 'is',\n",
              " 'are',\n",
              " 'was',\n",
              " 'were',\n",
              " 'be',\n",
              " 'been',\n",
              " 'being',\n",
              " 'have',\n",
              " 'has',\n",
              " 'had',\n",
              " 'having',\n",
              " 'do',\n",
              " 'does',\n",
              " 'did',\n",
              " 'doing',\n",
              " 'a',\n",
              " 'an',\n",
              " 'the',\n",
              " 'and',\n",
              " 'but',\n",
              " 'if',\n",
              " 'or',\n",
              " 'because',\n",
              " 'as',\n",
              " 'until',\n",
              " 'while',\n",
              " 'of',\n",
              " 'at',\n",
              " 'by',\n",
              " 'for',\n",
              " 'with',\n",
              " 'about',\n",
              " 'against',\n",
              " 'between',\n",
              " 'into',\n",
              " 'through',\n",
              " 'during',\n",
              " 'before',\n",
              " 'after',\n",
              " 'above',\n",
              " 'below',\n",
              " 'to',\n",
              " 'from',\n",
              " 'up',\n",
              " 'down',\n",
              " 'in',\n",
              " 'out',\n",
              " 'on',\n",
              " 'off',\n",
              " 'over',\n",
              " 'under',\n",
              " 'again',\n",
              " 'further',\n",
              " 'then',\n",
              " 'once',\n",
              " 'here',\n",
              " 'there',\n",
              " 'when',\n",
              " 'where',\n",
              " 'why',\n",
              " 'how',\n",
              " 'all',\n",
              " 'any',\n",
              " 'both',\n",
              " 'each',\n",
              " 'few',\n",
              " 'more',\n",
              " 'most',\n",
              " 'other',\n",
              " 'some',\n",
              " 'such',\n",
              " 'no',\n",
              " 'nor',\n",
              " 'not',\n",
              " 'only',\n",
              " 'own',\n",
              " 'same',\n",
              " 'so',\n",
              " 'than',\n",
              " 'too',\n",
              " 'very',\n",
              " 's',\n",
              " 't',\n",
              " 'can',\n",
              " 'will',\n",
              " 'just',\n",
              " 'don',\n",
              " \"don't\",\n",
              " 'should',\n",
              " \"should've\",\n",
              " 'now',\n",
              " 'd',\n",
              " 'll',\n",
              " 'm',\n",
              " 'o',\n",
              " 're',\n",
              " 've',\n",
              " 'y',\n",
              " 'ain',\n",
              " 'aren',\n",
              " \"aren't\",\n",
              " 'couldn',\n",
              " \"couldn't\",\n",
              " 'didn',\n",
              " \"didn't\",\n",
              " 'doesn',\n",
              " \"doesn't\",\n",
              " 'hadn',\n",
              " \"hadn't\",\n",
              " 'hasn',\n",
              " \"hasn't\",\n",
              " 'haven',\n",
              " \"haven't\",\n",
              " 'isn',\n",
              " \"isn't\",\n",
              " 'ma',\n",
              " 'mightn',\n",
              " \"mightn't\",\n",
              " 'mustn',\n",
              " \"mustn't\",\n",
              " 'needn',\n",
              " \"needn't\",\n",
              " 'shan',\n",
              " \"shan't\",\n",
              " 'shouldn',\n",
              " \"shouldn't\",\n",
              " 'wasn',\n",
              " \"wasn't\",\n",
              " 'weren',\n",
              " \"weren't\",\n",
              " 'won',\n",
              " \"won't\",\n",
              " 'wouldn',\n",
              " \"wouldn't\"]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "GB0LWMtFvgM8"
      },
      "outputs": [],
      "source": [
        "from pyresparser import ResumeParser as rp\n",
        "import os\n",
        "from docx import Document as dc"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "file_directory = '/content/drive/MyDrive/Kaggle/Jalal_Rahmanov_Resume.pdf'"
      ],
      "metadata": {
        "id": "1t8_y2rDv6o2"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_directory"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "5MZ2Uzrl6nFy",
        "outputId": "50298a37-1f83-43a0-9d74-247ea81c2a35"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/Kaggle/Jalal_Rahmanov_Resume.pdf'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  doc = dc()\n",
        "  with open(file_directory, 'r') as file:\n",
        "    doc.add_paragraph(file.read())\n",
        "  doc.save('text.docx')\n",
        "  data = rp('text.docx').get_extracted_data()\n",
        "  print(data['skills'])\n",
        "except:\n",
        "  data = rp(file_directory).get_extracted_data()\n",
        "  print(data['skills'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OturZfQfzISe",
        "outputId": "7a83ec44-8b0a-4b6e-e1dd-101d098dd3f5"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['R', 'German', 'Statistics', 'Excel', 'Analytics', 'Hadoop', 'Data analysis', 'Analysis', 'Engineering', 'Programming', 'Ubuntu', 'Docker', 'Machine learning', 'Python', 'English', 'Mobile', 'Sql', 'Github', 'Communication', 'Accounting', 'Big data', 'C']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Nyil7QG0tyA",
        "outputId": "716687e2-ac4f-449c-816a-74b9e9ec58be"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'college_name': None,\n",
              " 'company_names': None,\n",
              " 'degree': None,\n",
              " 'designation': None,\n",
              " 'email': 'rehmanov.celal@gmail.com',\n",
              " 'experience': ['Data Science intern at QSS Analytics',\n",
              "  'Mainly: Python mentoring in trainings that were organized by QSS',\n",
              "  'Analytics and Data Science Academy. Worked on many cases about',\n",
              "  'Machine Learning and Deep Learning(AI).',\n",
              "  'Secondary: learned SQL, Big Data, GitHub, Hadoop, Docker, Ubuntu. Also',\n",
              "  'did junior accounting using Excel and Google Spreadsheet and, many',\n",
              "  'office supplies tasks during 3 months of internship program.',\n",
              "  'Data Science & Business Analytics virtual internship at The Sparks',\n",
              "  'Foundation (virtual)',\n",
              "  'Gave solutions to the problems of Machine Learning',\n",
              "  'Build an excellent profile on Linkedln during 1 month as a task',\n",
              "  'Data Science Intern, Khasay Mirzali, DataStat, Baku',\n",
              "  'Learned basics of Machine Learning',\n",
              "  'Did many tasks in R programming language',\n",
              "  'Improved data collection methods by designing surveys in Google',\n",
              "  'Forms',\n",
              "  'Speciality Certificates',\n",
              "  'Data Science Academy - Python (mentorship)',\n",
              "  'Qss Analytics - Python (mentorship)',\n",
              "  'Data Science Academy - SQL',\n",
              "  'Coursera – Prepare Data for Exploration – authorized by Google',\n",
              "  'Coursera – Ask Questions to Make Data-Driven Decisions –',\n",
              "  'authorized by Google',\n",
              "  'Coursera - Foundations: Data, Data Everywhere – authorized by',\n",
              "  'Google',\n",
              "  'DataStat – Certificate of Completion – instructor Khasay Mirzali',\n",
              "  'Kaggle – Intermediate Machine Learning',\n",
              "  'Kaggle – Intro to Machine Learning',\n",
              "  'Kaggle – Python Intermediate',\n",
              "  'Udemy – Data Analysis & Statistics: practical course for beginners',\n",
              "  'Certificate form Baku Engineering University – 600 hours intensive',\n",
              "  'English Language Program – B2(CEF)'],\n",
              " 'mobile_number': None,\n",
              " 'name': 'D A',\n",
              " 'no_of_pages': 1,\n",
              " 'skills': ['R',\n",
              "  'German',\n",
              "  'Statistics',\n",
              "  'Excel',\n",
              "  'Analytics',\n",
              "  'Hadoop',\n",
              "  'Data analysis',\n",
              "  'Analysis',\n",
              "  'Engineering',\n",
              "  'Programming',\n",
              "  'Ubuntu',\n",
              "  'Docker',\n",
              "  'Machine learning',\n",
              "  'Python',\n",
              "  'English',\n",
              "  'Mobile',\n",
              "  'Sql',\n",
              "  'Github',\n",
              "  'Communication',\n",
              "  'Accounting',\n",
              "  'Big data',\n",
              "  'C'],\n",
              " 'total_experience': 0.0}"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Thank You!"
      ],
      "metadata": {
        "id": "HHRlapLD1m5c"
      }
    }
  ]
}